{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout,Conv2DTranspose,concatenate,Cropping2D, ReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, size=(size, size)):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img)[:, :, :1]\n",
    "    if size:\n",
    "        img = tf.image.resize(img, size)\n",
    "    mean_ = tf.math.reduce_mean(img)\n",
    "    std_ = tf.math.reduce_std(img)\n",
    "    return (tf.cast(img, 'float32') - mean_) / std_\n",
    "\n",
    "def load_label(img_path, size=(size, size)):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img)[:, :, :1]\n",
    "    if size:\n",
    "        img = tf.image.resize(img, size)\n",
    "    return tf.cast(img > 10, 'int64')\n",
    "\n",
    "\n",
    "def load_val_image(img_path, size=(1280, 1280)):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img)[:, :, :1]\n",
    "    if size:\n",
    "        img = tf.image.resize(img, size)\n",
    "    return (tf.cast(img, 'float32') - 128.) / 27.\n",
    "    \n",
    "\n",
    "def load_val_label(img_path, size=None):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img)\n",
    "    if size:\n",
    "        img = tf.image.resize(img, size)\n",
    "    return tf.cast(img > 10, 'int64')\n",
    "\n",
    "\n",
    "def _get_dataset(file_pattern, load_file):\n",
    "    dataset = tf.data.Dataset.list_files(file_pattern, shuffle=False)\n",
    "    dataset = dataset.map(load_file)\n",
    "    return dataset\n",
    "\n",
    "def sample_division(image, label, threshold=10):\n",
    "    return tf.cast(tf.reduce_sum(label) > threshold, 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_ds(file_pattern, load_file):\n",
    "    dataset_fp = tf.data.Dataset.list_files(file_pattern, shuffle=False)\n",
    "    dataset_img = dataset_fp.map(load_file)\n",
    "    return dataset_fp, dataset_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(image_dir, label_dir, batch_size, shuffle_size=10):\n",
    "    image_dataset = _get_dataset(image_dir+'*.jpg', load_image)\n",
    "    label_dataset = _get_dataset(label_dir+'*.png', load_label)\n",
    "    pair_dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "    return pair_dataset.shuffle(buffer_size=shuffle_size).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "def unet(pretrained_weights=None, input_size=(size, size, 1), padding='same', base=24):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(base*1, 5, padding=padding, dilation_rate=1)(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = Conv2D(base*1, 3, padding=padding, dilation_rate=1)(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(base*2, 3, padding=padding, dilation_rate=3)(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = Conv2D(base*2, 3, padding=padding, dilation_rate=3)(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    \n",
    "    conv3 = Conv2D(base*4, 3, padding=padding, dilation_rate=2)(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = Conv2D(base*4, 3, padding=padding, dilation_rate=2)(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "    \n",
    "    conv4 = Conv2D(base*8, 3, padding=padding, dilation_rate=2)(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = Conv2D(base*8, 3, padding=padding, dilation_rate=2)(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(base*16, 3, padding=padding, dilation_rate=2)(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = ReLU()(conv5)\n",
    "    conv5 = Conv2D(base*16, 3, padding=padding, dilation_rate=1)(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = ReLU()(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2DTranspose(base*16, 3, activation='relu', padding='same', strides=(2, 2),)(drop5)\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(base*8, 3, activation='relu', padding=padding, dilation_rate=1)(merge6)\n",
    "    conv6 = BatchNormalization()(merge6)\n",
    "    conv6 = Conv2D(base*8, 3, activation='relu', padding=padding, dilation_rate=2)(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    drop6 = Dropout(0.5)(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(base*4, 3, activation='relu', padding='same', strides=(2, 2),)(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(base*4, 3, activation='relu', padding=padding, dilation_rate=1)(merge7)\n",
    "    conv7 = BatchNormalization()(merge7)\n",
    "    conv7 = Conv2D(base*4, 3, activation='relu', padding=padding, dilation_rate=2)(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    drop7 = Dropout(0.5)(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(base*2, 3, activation='relu', padding='same', strides=(2, 2),)(conv7)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(base*2, 3, activation='relu', padding=padding, dilation_rate=1)(merge8)\n",
    "    conv8 = BatchNormalization()(merge8)\n",
    "    conv8 = Conv2D(base*2, 3, activation='relu', padding=padding, dilation_rate=1)(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    drop8 = Dropout(0.5)(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(base*1, 3, activation='relu', padding='same', strides=(2, 2),)(conv8)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(base*1, 3, activation='relu', padding=padding, dilation_rate=1)(merge9)\n",
    "    conv9 = BatchNormalization()(merge9)\n",
    "    conv9 = Conv2D(base*1, 3, activation='relu', padding=padding, dilation_rate=1)(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(base*1, 3, activation='relu', padding=padding, dilation_rate=1)(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(1, 1, activation='sigmoid', padding=padding,)(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=conv9)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "label_dir = 'my_data/train_mask/'\n",
    "image_dir = 'my_data/train_img/'\n",
    "val_image_dir = 'my_data/valid_img/'\n",
    "val_label_dir = 'my_data/valid_mask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(image_dir, label_dir, batch_size)\n",
    "valid_dataset = get_dataset(val_image_dir, val_label_dir, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilearning_rate = 1e-2\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        return ilearning_rate*1e-2\n",
    "    elif epoch < 10:\n",
    "        return ilearning_rate\n",
    "    elif epoch < 50:\n",
    "        return ilearning_rate * 0.1\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=ilearning_rate, momentum=0.95), loss=tf.keras.losses.mean_absolute_error, metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, validation_data= valid_dataset, verbose=1,  epochs=100,callbacks=[callback])\n",
    "model.evaluate(valid_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('pth/seg_unet_09801.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
