{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hand_bone_labels_last.csv', dtype={'file':str, 'far-phalanx3':'int64', 'far-phalanx5':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number = 15\n",
    "category_number = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = 'hand_bone_for_classfication_resized_img/'\n",
    "bone_cates = ['far-phalanx1', 'far-phalanx3', 'far-phalanx5', 'metacarpal1',\n",
    "       'metacarpal3', 'metacarpal5', 'middle-phalanx3', 'middle-phalanx5',\n",
    "       'nearly-phalanx1', 'nearly-phalanx3', 'nearly-phalanx5', 'radius',\n",
    "       'ulna']\n",
    "def load_preprosess_image(img_idx, img_shape=[256, 256]):\n",
    "    imgs = []\n",
    "    for cate in bone_cates:\n",
    "        img_path = imgs_dir + img_idx + '-' + cate + '.jpg'\n",
    "        img = tf.io.read_file(img_path) \n",
    "        img = tf.image.decode_jpeg(img,channels=1)  \n",
    "        img = tf.image.resize(img, img_shape) \n",
    "        img = tf.reshape(img, img_shape)\n",
    "        img = tf.cast(img, tf.float32) \n",
    "        img = img/255.\n",
    "        imgs.append(img)\n",
    "    return tf.stack(imgs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids_file = 'inds_cnt_13_last.txt'\n",
    "\n",
    "with open(img_ids_file, 'r') as f:\n",
    "    img_ids = f.read()\n",
    "img_ids = img_ids.split('\\n')\n",
    "\n",
    "random.shuffle(img_ids)\n",
    "_N = int(len(img_ids) * 0.8)\n",
    "train_ids = img_ids[:_N]\n",
    "val_ids = img_ids[_N:]\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_img_ds = tf.data.Dataset.from_tensor_slices(train_ids)\n",
    "train_img_ds = train_img_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)\n",
    "# train_img_ds = train_img_ds.batch(BATCH_SIZE)\n",
    "train_img_ds = train_img_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "val_img_ds = tf.data.Dataset.from_tensor_slices(val_ids)\n",
    "val_img_ds = val_img_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)\n",
    "# val_img_ds = val_img_ds.batch(BATCH_SIZE)\n",
    "val_img_ds = val_img_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number2onehot(number):\n",
    "    dff = df.set_index('file')\n",
    "    label_number = dff.loc[number].to_numpy()\n",
    "    return np.eye(class_number)[label_number].reshape((-1, category_number*class_number))\n",
    "\n",
    "def onehot2number(res):\n",
    "    return np.argmax(res.reshape((-1, category_number, class_number)), axis=-1)\n",
    "\n",
    "train_label = number2onehot(train_ids)\n",
    "val_label = number2onehot(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "shuffle_capcity = 100\n",
    "\n",
    "train_label_ds = tf.data.Dataset.from_tensor_slices(train_label)\n",
    "val_label_ds = tf.data.Dataset.from_tensor_slices(val_label)\n",
    "\n",
    "train_ds = tf.data.Dataset.zip((train_img_ds, train_label_ds))\n",
    "val_ds = tf.data.Dataset.zip((val_img_ds, val_label_ds))\n",
    "\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "trian_ds = train_ds.shuffle(shuffle_capcity)\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_1(tf.keras.Model):\n",
    "    def __init__(self, batch_size, bn_axis=-1):\n",
    "        super(Dense_1, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.pad1 =  layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name='densenet_1_pad')\n",
    "        self.conv1 =  layers.Conv2D(64, 3, strides=1, use_bias=False, name='densenet_1_conv')\n",
    "        self.bn = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='densenet_1_bn')\n",
    "        self.relu = x = layers.Activation('relu', name='densenet_1_relu')\n",
    "        self.pad2 = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='densenet_1_pad_2')\n",
    "        self.pool = layers.MaxPooling2D(3, strides=2, name='densenet_1_pool_1')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.gather(x, indices=tf.range(self.batch_size))\n",
    "        x = tf.reshape(x, (-1, 256, 256, 1), name='densenet_1_reshape')\n",
    "        x = self.pad1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pad2(x)\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_conv_block(tf.keras.Model):\n",
    "    def __init__(self, growth_rate, name, bn_axis=-1):\n",
    "        super(Dense_conv_block, self).__init__()\n",
    "        self.bn1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')\n",
    "        self.a1 = layers.Activation('relu', name=name + '_1_relu')\n",
    "        self.c1 = layers.Conv2D(4 * growth_rate, 1, use_bias=False, name=name + '_1_conv')\n",
    "        self.bn2 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')\n",
    "        self.a2 = layers.Activation('relu', name=name + '_2_relu')\n",
    "        self.c2 = layers.Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_2_conv')\n",
    "        self.concat = layers.Concatenate(axis=bn_axis, name=name + '_concat')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x1 = self.bn1(x)\n",
    "        x1 = self.a1(x1)\n",
    "        x1 = self.c1(x1)\n",
    "        x1 = self.bn2(x1)\n",
    "        x1 = self.a2(x1)\n",
    "        x1 = self.c2(x1)\n",
    "        x = self.concat([x, x1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_transition_block(tf.keras.Model):\n",
    "    def __init__(self,filters, name, bn_axis=-1):\n",
    "        super(Dense_transition_block, self).__init__()\n",
    "        self.bn = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_bn')\n",
    "        self.a = layers.Activation('relu', name=name + '_relu')\n",
    "        self.c = layers.Conv2D(filters,1,use_bias=False,name=name + '_conv')\n",
    "        self.p = layers.AveragePooling2D(2, strides=2, name=name + '_pool')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.a(x)\n",
    "        x = self.c(x)\n",
    "        x = self.p(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_block(tf.keras.Model):\n",
    "    def __init__(self, blocks, name):\n",
    "        super(Dense_block, self).__init__()\n",
    "        self.convs = []\n",
    "        self.blocks = blocks\n",
    "        for i in range(blocks):\n",
    "            self.convs.append(Dense_conv_block(32, name=name + '_block' + str(i + 1)))\n",
    "    \n",
    "    def call(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            x = self.convs[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "        blocks,\n",
    "        batch_size,\n",
    "        bn_axis=-1,\n",
    "        classes=category_number*class_number):\n",
    "        \n",
    "        super(DenseNet, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.d1 = Dense_1(batch_size=self.batch_size)\n",
    "        self.d2 = Dense_block(blocks[0], name='densenet_2')\n",
    "        self.t2 = Dense_transition_block(blocks[0], name='transition_2')\n",
    "        self.d3 = Dense_block(blocks[1], name='densenet_3')\n",
    "        self.t3 = Dense_transition_block(blocks[1], name='transition_3')\n",
    "        self.d4 = Dense_block(blocks[2], name='densenet_4')\n",
    "        self.t4 = Dense_transition_block(blocks[2], name='transition_4')\n",
    "        self.d5 = Dense_block(blocks[3], name='densenet_5')\n",
    "\n",
    "        self.bn6 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='fc_bn6')\n",
    "        self.a6 = layers.Activation('relu', name='fc_relu6')\n",
    "        self.avg_pool = layers.GlobalAveragePooling2D(name='fc_avg_pool')\n",
    "\n",
    "        self.pred = layers.Dense(classes, activation='sigmoid', name='predictions')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.t2(x)\n",
    "        x = self.d3(x)\n",
    "        x = self.t3(x)\n",
    "        x = self.d4(x)\n",
    "        x = self.t4(x)\n",
    "        x = self.d5(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.a6(x)\n",
    "        x = self.avg_pool(x)\n",
    "        \n",
    "        x = tf.gather(x, indices=tf.range(category_number*self.batch_size))\n",
    "        x = tf.reshape(x, (self.batch_size, -1))\n",
    "        x = self.pred(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DenseNet(blocks=[4, 8, 16, 16], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd.load_weights('M_dense_1_63_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam = tf.optimizers.Adam(lr=1e-4)\n",
    "sgd = tf.optimizers.SGD(learning_rate=1e-4,momentum=0.95)\n",
    "dd.compile(optimizer=sgd, loss='binary_crossentropy', metrics='acc')\n",
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd.save_weights('M_dense_1_63_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.fit(train_ds, validation_data=val_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
